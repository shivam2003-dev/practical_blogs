{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udf93 WILP MTech AI/ML Knowledge Base","text":"<p>Welcome to the comprehensive knowledge base for the WILP MTech AI/ML program!</p> <p>This documentation is organized by semester and subject, providing in-depth coverage of mathematical foundations, machine learning, statistical methods, and deep neural networks.</p>"},{"location":"#semester-1","title":"\ud83d\udcda Semester 1","text":"<p>Explore the four core subjects:</p>"},{"location":"#mathematical-foundations","title":"\ud83e\uddee Mathematical Foundations","text":"<p>Core mathematical concepts essential for AI and ML.</p>"},{"location":"#machine-learning","title":"\ud83e\udd16 Machine Learning","text":"<p>Fundamental machine learning concepts and techniques.</p>"},{"location":"#statistical-methods","title":"\ud83d\udcca Statistical Methods","text":"<p>Statistical theory and methods for data analysis.</p>"},{"location":"#deep-neural-networks","title":"\ud83e\udde0 Deep Neural Networks","text":"<p>Deep learning architectures and advanced AI techniques.</p> <p>\ud83d\udca1 Use the navigation sidebar to explore all topics and sections.</p>"},{"location":"semester-1/deep-neural-networks/","title":"\ud83e\udde0 Deep Neural Networks","text":"<p>Deep learning architectures, neural network training, and advanced AI techniques.</p>"},{"location":"semester-1/deep-neural-networks/#topics","title":"Topics","text":"<ul> <li>Perceptron - Single-layer neural networks</li> <li>CNN - Convolutional Neural Networks</li> <li>RNN - Recurrent Neural Networks</li> <li>Optimization - Optimization techniques for neural networks</li> <li>Transfer Learning - Transfer learning approaches</li> </ul> <p>\ud83d\udcda References</p>"},{"location":"semester-1/deep-neural-networks/references/","title":"\ud83d\udcda References","text":""},{"location":"semester-1/deep-neural-networks/references/#textbooks","title":"Textbooks","text":"<p>References will be added as content expands.</p>"},{"location":"semester-1/deep-neural-networks/topics/cnn/","title":"\ud83d\uddbc\ufe0f Convolutional Neural Networks (CNN)","text":"<p>Content coming soon...</p>"},{"location":"semester-1/deep-neural-networks/topics/optimization/","title":"\u2699\ufe0f Optimization","text":"<p>Content coming soon...</p>"},{"location":"semester-1/deep-neural-networks/topics/perceptron/","title":"\ud83e\udde0 Perceptron","text":"<p>Content coming soon...</p>"},{"location":"semester-1/deep-neural-networks/topics/rnn/","title":"\ud83d\udd04 Recurrent Neural Networks (RNN)","text":"<p>Content coming soon...</p>"},{"location":"semester-1/deep-neural-networks/topics/transfer-learning/","title":"\ud83d\udd04 Transfer Learning","text":"<p>Content coming soon...</p>"},{"location":"semester-1/machine-learning/","title":"\ud83e\udd16 Machine Learning","text":"<p>Fundamental machine learning concepts, algorithms, and techniques for building intelligent systems.</p>"},{"location":"semester-1/machine-learning/#topics","title":"Topics","text":"<ul> <li>Supervised Learning - Classification and regression algorithms</li> <li>Unsupervised Learning - Clustering and dimensionality reduction</li> <li>Model Evaluation - Metrics and validation techniques</li> <li>Feature Engineering - Feature selection and transformation</li> <li>ML Pipelines - End-to-end ML workflows</li> </ul> <p>\ud83d\udcda References</p>"},{"location":"semester-1/machine-learning/references/","title":"\ud83d\udcda References","text":""},{"location":"semester-1/machine-learning/references/#textbooks","title":"Textbooks","text":"<p>References will be added as content expands.</p>"},{"location":"semester-1/machine-learning/topics/feature-engineering/","title":"\ud83d\udd27 Feature Engineering","text":"<p>Content coming soon...</p>"},{"location":"semester-1/machine-learning/topics/ml-pipelines/","title":"\ud83d\udd04 ML Pipelines","text":"<p>Content coming soon...</p>"},{"location":"semester-1/machine-learning/topics/model-evaluation/","title":"\ud83d\udcc8 Model Evaluation","text":"<p>Content coming soon...</p>"},{"location":"semester-1/machine-learning/topics/pca-fit-transform/","title":"\ud83d\udd2c Principal Component Analysis (PCA)","text":""},{"location":"semester-1/machine-learning/topics/pca-fit-transform/#what-fit-does","title":"\u2699\ufe0f What <code>.fit()</code> does","text":"<p><code>pca.fit()</code> = \"Learn\" from the data.</p> <p>When you call:</p> <pre><code>pca.fit(scaled_data)\n</code></pre> <p>PCA:</p> <ul> <li>Computes the mean of each feature</li> <li>Calculates the covariance matrix</li> <li>Finds the eigenvectors and eigenvalues</li> <li>Selects the top 2 components (since <code>n_components=2</code>) that explain most variance</li> </ul> <p>\ud83d\udc49 In short: <code>fit()</code> finds the directions of maximum variance \u2014 i.e., the new coordinate system (axes).</p> <p>Think of this as training PCA on your data.</p>"},{"location":"semester-1/machine-learning/topics/pca-fit-transform/#what-transform-does","title":"\u2699\ufe0f What <code>.transform()</code> does","text":"<p><code>pca.transform()</code> = \"Apply\" what was learned.</p> <p>When you call:</p> <pre><code>scaled_pca = pca.transform(scaled_data)\n</code></pre> <p>PCA:</p> <ul> <li>Projects each data point onto the new principal components found during <code>fit()</code></li> <li>Gives you new coordinates (in the new 2D PCA space)</li> </ul> <p>\ud83d\udc49 In short: <code>transform()</code> converts your original features into PCA components (new columns like PC1, PC2).</p>"},{"location":"semester-1/machine-learning/topics/supervised-learning/","title":"\ud83d\udcca Supervised Learning","text":"<p>Content coming soon...</p>"},{"location":"semester-1/machine-learning/topics/unsupervised-learning/","title":"\ud83d\udd0d Unsupervised Learning","text":"<p>Content coming soon...</p>"},{"location":"semester-1/mathematical-foundations/","title":"\ud83e\uddee Mathematical Foundations","text":"<p>Core mathematical concepts essential for AI and ML, including linear algebra, calculus, probability, and optimization.</p>"},{"location":"semester-1/mathematical-foundations/#topics","title":"Topics","text":"<ul> <li>Linear Algebra - Systems of linear equations, row reduction, and solution sets</li> <li>Set Theory - Fundamental set operations and concepts</li> <li>Probability - Probability theory and distributions</li> <li>Logic - Mathematical logic and proof techniques</li> </ul> <p>\ud83d\udcda References</p>"},{"location":"semester-1/mathematical-foundations/references/","title":"\ud83d\udcda References","text":""},{"location":"semester-1/mathematical-foundations/references/#textbooks","title":"Textbooks","text":"<ul> <li>Lay, D. C., Lay, S. R., &amp; McDonald, J. (2016). Linear Algebra and Its Applications (5th ed.). Pearson.</li> </ul>"},{"location":"semester-1/mathematical-foundations/references/#online-resources","title":"Online Resources","text":"<ul> <li>Khan Academy - Linear Algebra</li> <li>MIT OpenCourseWare - Linear Algebra</li> </ul>"},{"location":"semester-1/mathematical-foundations/references/#additional-reading","title":"Additional Reading","text":"<p>References will be added as content expands.</p>"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/","title":"\ud83e\uddee Linear Algebra Summary Notes","text":""},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#lay-sections-1115-systems-row-reduction-and-solution-sets","title":"(Lay, Sections 1.1\u20131.5 \u2014 Systems, Row Reduction, and Solution Sets)","text":""},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#1-systems-of-linear-equations","title":"\ud83d\udcd8 1\ufe0f\u20e3 Systems of Linear Equations","text":"<p>A system of equations can be written as:</p> <p>$$ A\\mathbf{x} = \\mathbf{b} $$</p> <p>where  </p> <ul> <li>A \u2192 coefficient matrix  </li> <li>x \u2192 vector of variables  </li> <li>b \u2192 constants vector  </li> </ul>"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#types-of-solutions","title":"\u2733\ufe0f Types of Solutions","text":"Type Meaning Matrix Condition Unique Exactly one solution Pivot in every variable column No solution Inconsistent equations Row $[0 \\; 0 \\; 0 \\mid c]$ where $c \\neq 0$ Infinite Many solutions At least one free variable"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#2-row-reduction-echelon-forms","title":"\u2699\ufe0f 2\ufe0f\u20e3 Row Reduction &amp; Echelon Forms","text":"<p>Row operations simplify a system without changing its solutions.</p>"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#echelon-form-ref","title":"\ud83d\udd39 Echelon Form (REF)","text":"<p>A matrix is in echelon form if: 1. All nonzero rows are above any zero rows 2. Each leading (first nonzero) entry of a row is to the right of the leading entry above it 3. All entries below a leading entry are zero</p>"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#reduced-row-echelon-form-rref","title":"\ud83d\udd39 Reduced Row-Echelon Form (RREF)","text":"<p>A matrix in echelon form is reduced if it also satisfies: 4. Each leading entry is 1 5. Each leading 1 is the only nonzero entry in its column  </p> <p>\ud83d\udc49 All RREF matrices are also REF, but not vice versa.</p>"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#3-pivots-pivot-positions-and-pivot-columns","title":"\ud83d\udccd 3\ufe0f\u20e3 Pivots, Pivot Positions, and Pivot Columns","text":"Term Meaning Pivot A leading nonzero entry in a row (usually made 1) Pivot position The (row, column) location of that pivot Pivot column Column containing a pivot position <ul> <li>Pivot columns \u2192 basic variables </li> <li>Non-pivot columns \u2192 free variables</li> </ul>"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#4-free-variables","title":"\ud83d\udd13 4\ufe0f\u20e3 Free Variables","text":"<p>A free variable is a variable that does not have a pivot in its column. It can take any value (usually represented by a parameter like <code>t</code> or <code>s</code>).</p>"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#example","title":"\ud83e\uddee Example","text":"<p>From the RREF:</p> <p>$$ \\begin{bmatrix} 1 &amp; 3 &amp; 0 &amp; \\mid &amp; -5 \\ 0 &amp; 0 &amp; 1 &amp; \\mid &amp; 3 \\end{bmatrix} $$</p> <p>Variables: $x_1, x_2, x_3$</p> <ul> <li>Pivots \u2192 column 1 ($x_1$), column 3 ($x_3$)  </li> <li>Free variable \u2192 $x_2 = t$</li> </ul> <p>So:</p> <p>$$ x_1 = -5 - 3t, \\quad x_3 = 3 $$</p> <p>Vector form:</p> <p>$$ \\mathbf{x} = \\begin{bmatrix} -5 \\ 0 \\ 3 \\end{bmatrix} + t \\begin{bmatrix} -3 \\ 1 \\ 0 \\end{bmatrix}, \\quad t \\in \\mathbb{R} $$</p> <p>\u27a1\ufe0f Each free variable adds one dimension (a line, plane, etc.) to the solution set.</p>"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#5-homogeneous-systems","title":"\u2696\ufe0f 5\ufe0f\u20e3 Homogeneous Systems","text":"<p>A system of the form:</p> <p>$$ A\\mathbf{x} = 0 $$</p> <ul> <li>Always has the trivial solution ($\\mathbf{x} = 0$)  </li> <li>If there are free variables, then there are infinitely many (non-trivial) solutions  </li> </ul> <p>The solution set is a subspace (line, plane, etc.) through the origin.</p>"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#6-summary-of-solution-types","title":"\ud83d\udcca 6\ufe0f\u20e3 Summary of Solution Types","text":"Condition System Type # of Solutions Description No contradictory row Consistent 1 or \u221e Has solution(s) Contradictory row ($[0 \\; 0 \\; 0 \\mid c]$ where $c \\neq 0$) Inconsistent 0 No solution Pivot in every variable column Consistent 1 Unique Free variables exist Consistent \u221e Infinite (parametric)"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#7-importance-of-ref-rref-in-machine-learning","title":"\ud83d\udcbb 7\ufe0f\u20e3 Importance of REF &amp; RREF in Machine Learning","text":""},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#what-they-do","title":"\ud83d\udca1 What They Do","text":"<p>REF and RREF simplify a data or coefficient matrix to reveal: - which features are independent (pivot columns) - which features are redundant (free columns) - how many independent directions exist (rank)</p>"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#why-it-matters-in-ml","title":"\ud83d\udd0d Why It Matters in ML","text":"Concept Meaning Machine-Learning Insight Pivot columns Independent variables/features Identify useful features Free variables Redundant/dependent features Detect multicollinearity Rank (# of pivots) Effective information content Measures data dimensionality RREF/REF Simplified version of system Makes solving equations efficient"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#real-world-ml-examples","title":"\ud83e\udde0 Real-World ML Examples","text":"Example REF/RREF Role Linear Regression Solving $A^TAx = A^Tb$ uses elimination (RREF idea) Feature Selection Detects redundant or correlated features PCA (Dimensionality Reduction) Finds independent \"pivot\" directions Neural Networks Rank of weight matrices shows information capacity Data Cleaning Removes duplicate features or dependent rows"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#8-key-takeaways","title":"\ud83c\udfaf 8\ufe0f\u20e3 Key Takeaways","text":"<ul> <li>REF/RREF simplify systems to show independent relationships </li> <li>Pivot columns = essential, independent features  </li> <li>Free variables = redundant or dependent features  </li> <li>Rank (number of pivots) = true dimensionality of data  </li> </ul> <p>In machine learning this helps: - Build stable regression models - Detect redundant features - Reduce data dimensionality - Understand whether a system is solvable uniquely  </p>"},{"location":"semester-1/mathematical-foundations/topics/linear-algebra/#9-quick-formula-recap","title":"\ud83e\udde9 9\ufe0f\u20e3 Quick Formula Recap","text":"Concept Formula Meaning Rank(A) number of pivots Measures independence Free variables $n - \\text{rank}(A)$ Number of parameters in general solution Unique solution $\\text{rank}(A) = n$ One exact solution Infinite solutions $\\text{rank}(A) &lt; n$ (consistent) Many solutions <p>\ud83e\udde0 Think of RREF as the \"X-ray\" of your data or equations: It reveals the independent skeleton of information hiding inside your matrix. Machine learning uses these same ideas to understand, compress, and clean data.</p>"},{"location":"semester-1/mathematical-foundations/topics/logic/","title":"\ud83d\udd0d Logic","text":"<p>Content coming soon...</p>"},{"location":"semester-1/mathematical-foundations/topics/probability/","title":"\ud83c\udfb2 Probability","text":"<p>Content coming soon...</p>"},{"location":"semester-1/mathematical-foundations/topics/set-theory/","title":"\ud83d\udcda Set Theory","text":"<p>Content coming soon...</p>"},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/","title":"\ud83e\udde9 System of Two Linear Equations (2 Variables)","text":""},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#problem-statement","title":"\ud83d\udcd8 Problem Statement","text":"<p>Given a system of two linear equations with two unknowns $w_1$ and $w_2$:</p> <p>$$ a_1 w_1 + b_1 w_2 = c_1 $$</p> <p>$$ a_2 w_1 + b_2 w_2 = c_2 $$</p> <p>Determine whether:</p> <ul> <li>\u2705 There is a unique solution.</li> <li>\ud83d\udd01 There are infinitely many solutions.</li> <li>\u274c There is no solution.</li> </ul>"},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#concept","title":"\ud83e\udde0 Concept","text":"<p>Each equation represents a line in 2D space.</p> Case Description Geometric Meaning Unique Solution Lines intersect at exactly one point. Two lines cross once. Infinite Solutions Both equations describe the same line. Lines are coincident. No Solution Lines are parallel and never meet. Parallel lines."},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#approach-1-determinant-cramers-rule","title":"\u2699\ufe0f Approach 1 \u2014 Determinant (Cramer's Rule)","text":""},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#step-1-form-coefficient-matrix","title":"Step 1: Form Coefficient Matrix","text":"<p>$$ A = \\begin{bmatrix} a_1 &amp; b_1 \\ a_2 &amp; b_2 \\end{bmatrix} ,\\quad B = \\begin{bmatrix} c_1 \\ c_2 \\end{bmatrix} $$</p>"},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#step-2-compute-determinant","title":"Step 2: Compute Determinant","text":"<p>$$ D = a_1 b_2 - a_2 b_1 $$</p>"},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#step-3-check-cases","title":"Step 3: Check Cases","text":"Condition Result $D \\neq 0$ \u2705 Unique solution: $w_1 = \\frac{c_1 b_2 - c_2 b_1}{D}$, $w_2 = \\frac{a_1 c_2 - a_2 c_1}{D}$ $D = 0$ and ratios $\\frac{a_1}{a_2} = \\frac{b_1}{b_2} = \\frac{c_1}{c_2}$ \ud83d\udd01 Infinitely many solutions $D = 0$ but constants not in same ratio \u274c No solution"},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#approach-2-row-reduction-gaussian-elimination","title":"\u2699\ufe0f Approach 2 \u2014 Row Reduction (Gaussian Elimination)","text":"<p>Form augmented matrix:</p> <p>$$ \\begin{bmatrix} a_1 &amp; b_1 &amp; \\mid &amp; c_1 \\ a_2 &amp; b_2 &amp; \\mid &amp; c_2 \\end{bmatrix} $$</p> <p>Perform elementary row operations to get row-echelon form.</p> Form Meaning $[0 \\; 0 \\mid \\text{nonzero}]$ \u274c No solution $[0 \\; 0 \\mid 0]$ \ud83d\udd01 Infinite solutions No zero rows \u2705 Unique solution"},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#approach-3-graphical-slope-comparison","title":"\u2699\ufe0f Approach 3 \u2014 Graphical (Slope Comparison)","text":"<p>Each equation represents a line:</p> <p>$$ L_1: a_1 w_1 + b_1 w_2 = c_1 $$</p> <p>$$ L_2: a_2 w_1 + b_2 w_2 = c_2 $$</p> <p>Convert to slope-intercept form:</p> <p>$$ w_2 = -\\frac{a_1}{b_1} w_1 + \\frac{c_1}{b_1} $$</p> <p>$$ w_2 = -\\frac{a_2}{b_2} w_1 + \\frac{c_2}{b_2} $$</p> Condition Interpretation $m_1 \\neq m_2$ \u2705 Lines intersect once (unique solution) $m_1 = m_2$ and same intercept \ud83d\udd01 Infinite solutions $m_1 = m_2$ and different intercept \u274c No solution"},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#approach-4-rank-method-linear-algebra","title":"\u2699\ufe0f Approach 4 \u2014 Rank Method (Linear Algebra)","text":""},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#step-1-define-matrices","title":"Step 1: Define Matrices","text":"<p>$$ A = \\begin{bmatrix} a_1 &amp; b_1 \\ a_2 &amp; b_2 \\end{bmatrix} ,\\quad [A|B] = \\begin{bmatrix} a_1 &amp; b_1 &amp; \\mid &amp; c_1 \\ a_2 &amp; b_2 &amp; \\mid &amp; c_2 \\end{bmatrix} $$</p>"},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#step-2-compare-ranks","title":"Step 2: Compare Ranks","text":"Condition Result $\\text{rank}(A) = \\text{rank}([A B]) = 2$ $\\text{rank}(A) = \\text{rank}([A B]) &lt; 2$ $\\text{rank}(A) &lt; \\text{rank}([A B])$"},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#example-1-infinite-solutions","title":"\ud83e\uddee Example 1 \u2014 Infinite Solutions","text":"<p>$$ x + y = 2 $$</p> <p>$$ 2x + 2y = 4 $$</p> <p>Here, 2nd equation = 2 \u00d7 (1st equation)</p> <ul> <li>$\\text{rank}(A) = 1$  </li> <li>$\\text{rank}([A|B]) = 1$  </li> </ul> <p>\u2705 Infinitely many solutions</p>"},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#example-2-no-solution","title":"\ud83e\uddee Example 2 \u2014 No Solution","text":"<p>$$ x + y = 2 $$</p> <p>$$ 2x + 2y = 5 $$</p> <p>Here, coefficients have same ratio but constants don't.</p> <ul> <li>$\\text{rank}(A) = 1$  </li> <li>$\\text{rank}([A|B]) = 2$  </li> </ul> <p>\u274c No solution</p>"},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#example-3-unique-solution","title":"\ud83e\uddee Example 3 \u2014 Unique Solution","text":"<p>$$ x + y = 3 $$</p> <p>$$ x - y = 1 $$</p> <p>Determinant $D = (1)(-1) - (1)(1) = -2 \\neq 0$</p> <p>\u2705 Unique solution:</p> <p>$$ w_1 = 2, \\quad w_2 = 1 $$</p>"},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#python-implementation-determinant-method","title":"\ud83d\udcbb Python Implementation (Determinant Method)","text":"<pre><code>import numpy as np\n\ndef solve_linear_2x2(a1, b1, c1, a2, b2, c2):\n    D = a1 * b2 - a2 * b1\n    if abs(D) &gt; 1e-10:\n        w1 = (c1 * b2 - c2 * b1) / D\n        w2 = (a1 * c2 - a2 * c1) / D\n        return f\"Unique solution: w1 = {w1}, w2 = {w2}\"\n    else:\n        if (a1*b2 == a2*b1) and (a1*c2 == a2*c1):\n            return \"There are infinitely many solutions\"\n        else:\n            return \"Intersection does not exist\"\n\nprint(solve_linear_2x2(1, 1, 3, 1, -1, 1))\n</code></pre>"},{"location":"semester-1/mathematical-foundations/topics/system-two-linear-equations/#python-implementation-row-operations-method","title":"\ud83d\udcbb Python Implementation (Row Operations Method)","text":"<p>Alternative implementation using row operations (Gaussian elimination):</p> <pre><code>import numpy as np\n\ndef findIntersectionIfExists(e1: np.array, e2: np.array) -&gt; str:\n    \"\"\"\n    Solve system of 2 linear equations using row operations.\n\n    Args:\n        e1: numpy array [a1, b1, c1] representing a1*w1 + b1*w2 = c1\n        e2: numpy array [a2, b2, c2] representing a2*w1 + b2*w2 = c2\n\n    Returns:\n        String describing the solution or solution type\n    \"\"\"\n    # Scale e2 to match coefficient of w1 in e1\n    alpha = e1[0] / e2[0]\n    e2 = e2 * alpha\n\n    # Check if equations are identical (infinite solutions)\n    if (e2 == e1).all():\n        return \"There are infinitely many solutions\"\n\n    # Check if coefficients match but constants differ (no solution)\n    elif (e2[:2] == e1[:2]).all():\n        return \"Intersection does not exist\"\n\n    # Unique solution: subtract e1 from e2 and solve\n    else:\n        e2 = e2 - e1\n        w2 = e2[2] / e2[1]  # Solve for w2\n        w1 = (e1[2] - (e1[1] * w2)) / e1[0]  # Solve for w1\n        return '%.3f , %.3f' % (w1, w2)\n\n# Verify solution\ne1 = np.array([2, 4, 9])  # 2w1 + 4w2 = 9\ne2 = np.array([3, 7, 3])  # 3w1 + 7w2 = 3\nprint(findIntersectionIfExists(e1, e2))\n</code></pre> <p>How it works: 1. Scale the second equation to match the coefficient of $w_1$ in the first equation 2. Compare equations to detect infinite or no solution cases 3. Eliminate $w_1$ by subtracting equations, then solve for $w_2$ and back-substitute for $w_1$</p> <p>Example: - Input: $2w_1 + 4w_2 = 9$ and $3w_1 + 7w_2 = 3$ - Output: Unique solution $(w_1, w_2)$</p>"},{"location":"semester-1/statistical-methods/","title":"\ud83d\udcca Statistical Methods","text":"<p>Statistical theory and methods for data analysis, hypothesis testing, and making data-driven decisions.</p>"},{"location":"semester-1/statistical-methods/#topics","title":"Topics","text":"<ul> <li>Descriptive Statistics - Measures of central tendency and dispersion</li> <li>Hypothesis Testing - Statistical tests and significance</li> <li>Regression - Linear and non-linear regression</li> <li>Bayesian Inference - Bayesian statistics and inference</li> </ul> <p>\ud83d\udcda References</p>"},{"location":"semester-1/statistical-methods/references/","title":"\ud83d\udcda References","text":""},{"location":"semester-1/statistical-methods/references/#textbooks","title":"Textbooks","text":"<p>References will be added as content expands.</p>"},{"location":"semester-1/statistical-methods/topics/bayesian-inference/","title":"\ud83c\udfaf Bayesian Inference","text":"<p>Content coming soon...</p>"},{"location":"semester-1/statistical-methods/topics/descriptive-stats/","title":"\ud83d\udcc8 Descriptive Statistics","text":"<p>Content coming soon...</p>"},{"location":"semester-1/statistical-methods/topics/hypothesis-testing/","title":"\ud83d\udd2c Hypothesis Testing","text":"<p>Content coming soon...</p>"},{"location":"semester-1/statistical-methods/topics/regression/","title":"\ud83d\udcc9 Regression","text":"<p>Content coming soon...</p>"}]}